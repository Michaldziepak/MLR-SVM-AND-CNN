{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten,MaxPooling1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',100)\n",
    "Data = pd.read_excel(\"Otw4_mgr.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labeleddata = Data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(Data.columns.values)\n",
    "Labeleddata_withr8index = Labeleddata.reset_index(drop=True)#NAN DROP\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x = Labeleddata_withr8index.iloc[:,1:20].values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled)\n",
    "df.columns = features[1:20]\n",
    "\n",
    "non_standarized_data = Labeleddata_withr8index\n",
    "test_row_standarized = df.iloc[5:7]\n",
    "\n",
    "non_standarized_data = non_standarized_data.drop([5,6])\n",
    "TOC = non_standarized_data[\"TOC[%]\"]\n",
    "TOC = TOC.reset_index(drop=True) #31 elements of nonstandarized TOC\n",
    "\n",
    "test_row = Labeleddata_withr8index.iloc[5:7]#test rows 5,6+\n",
    "R8data= df.drop([5,6])# dropping 5 and 6 row in labeled data and creating R8data (31 elements)\n",
    "R8data = R8data.reset_index(drop=True)# reseting index for R8data\n",
    "\n",
    "\n",
    "\n",
    "#TOC = non_standarized_data[\"TOC[%]\"]#toc 31 elements\n",
    "\n",
    "TOC_row5=test_row[\"TOC[%]\"] # TOC 2 elements non standarized\n",
    "#R8data,Toc, test_row_standarized, TOC_row5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 19)\n"
     ]
    }
   ],
   "source": [
    "x, y = R8data, TOC\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 19, 1)\n"
     ]
    }
   ],
   "source": [
    "x = x.values.reshape(x.shape[0],x.shape[1],1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 18, 16)            48        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 9, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 8, 32)             1056      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 4, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 5,265\n",
      "Trainable params: 5,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(16, 2, activation=\"relu\", input_shape=(19,1)))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(32, 2, activation=\"relu\", input_shape=(19,1)))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "NAME = \"SIEC-{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 16.8702 - accuracy: 0.0000e+00\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 16.3388 - accuracy: 0.0000e+00\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 15.8104 - accuracy: 0.0000e+00\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 15.2873 - accuracy: 0.0000e+00\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 14.7927 - accuracy: 0.0000e+00\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 14.3154 - accuracy: 0.0000e+00\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 13.8416 - accuracy: 0.0000e+00\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 13.3790 - accuracy: 0.0000e+00\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.9253 - accuracy: 0.0000e+00\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.4821 - accuracy: 0.0000e+00\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.0467 - accuracy: 0.0000e+00\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 11.6234 - accuracy: 0.0000e+00\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.2156 - accuracy: 0.0000e+00\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.8329 - accuracy: 0.0000e+00\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 10.4581 - accuracy: 0.0000e+00\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 10.0907 - accuracy: 0.0000e+00\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.7330 - accuracy: 0.0000e+00\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.3861 - accuracy: 0.0000e+00\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.0513 - accuracy: 0.0000e+00\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.7373 - accuracy: 0.0000e+00\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.4434 - accuracy: 0.0000e+00\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.1751 - accuracy: 0.0000e+00\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.9322 - accuracy: 0.0000e+00\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 7.7078 - accuracy: 0.0000e+00\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.5024 - accuracy: 0.0000e+00\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.3152 - accuracy: 0.0000e+00\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1433 - accuracy: 0.0000e+00\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.9864 - accuracy: 0.0000e+00\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.8406 - accuracy: 0.0000e+00\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.7031 - accuracy: 0.0000e+00\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.5707 - accuracy: 0.0000e+00\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.4422 - accuracy: 0.0000e+00\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.3221 - accuracy: 0.0000e+00\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2069 - accuracy: 0.0000e+00\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0918 - accuracy: 0.0000e+00\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.9731 - accuracy: 0.0000e+00\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8490 - accuracy: 0.0000e+00\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7209 - accuracy: 0.0000e+00\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5877 - accuracy: 0.0000e+00\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4511 - accuracy: 0.0000e+00\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3120 - accuracy: 0.0000e+00\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.1710 - accuracy: 0.0000e+00\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.0284 - accuracy: 0.0000e+00\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.8850 - accuracy: 0.0000e+00\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 4.7416 - accuracy: 0.0000e+00\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5974 - accuracy: 0.0000e+00\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.4529 - accuracy: 0.0000e+00\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 4.3086 - accuracy: 0.0000e+00\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.1658 - accuracy: 0.0000e+00\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0232 - accuracy: 0.0000e+00\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8810 - accuracy: 0.0000e+00\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7403 - accuracy: 0.0000e+00\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.6017 - accuracy: 0.0000e+00\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.4646 - accuracy: 0.0000e+00\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.3280 - accuracy: 0.0000e+00\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.1914 - accuracy: 0.0000e+00\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.0550 - accuracy: 0.0000e+00\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.9202 - accuracy: 0.0000e+00\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.7891 - accuracy: 0.0000e+00\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.6606 - accuracy: 0.0000e+00\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.5342 - accuracy: 0.0000e+00\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4115 - accuracy: 0.0000e+00\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2921 - accuracy: 0.0000e+00\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1760 - accuracy: 0.0000e+00\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0636 - accuracy: 0.0000e+00\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.9561 - accuracy: 0.0000e+00\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8545 - accuracy: 0.0000e+00\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7580 - accuracy: 0.0000e+00\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6672 - accuracy: 0.0000e+00\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5826 - accuracy: 0.0000e+00\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5040 - accuracy: 0.0000e+00\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4319 - accuracy: 0.0000e+00\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.3661 - accuracy: 0.0000e+00\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.3065 - accuracy: 0.0000e+00\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2526 - accuracy: 0.0000e+00\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2047 - accuracy: 0.0000e+00\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1628 - accuracy: 0.0000e+00\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1267 - accuracy: 0.0000e+00\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0960 - accuracy: 0.0000e+00\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0702 - accuracy: 0.0000e+00\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 1.0485 - accuracy: 0.0000e+00\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0306 - accuracy: 0.0000e+00\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0163 - accuracy: 0.0000e+00\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0049 - accuracy: 0.0000e+00\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9955 - accuracy: 0.0000e+00\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9877 - accuracy: 0.0000e+00\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9813 - accuracy: 0.0000e+00\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9766 - accuracy: 0.0000e+00\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9724 - accuracy: 0.0000e+00\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.9685 - accuracy: 0.0000e+00\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9648 - accuracy: 0.0000e+00\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9605 - accuracy: 0.0000e+00\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9558 - accuracy: 0.0000e+00\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.9503 - accuracy: 0.0000e+00\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9442 - accuracy: 0.0000e+00\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9368 - accuracy: 0.0000e+00\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9287 - accuracy: 0.0000e+00\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9217 - accuracy: 0.0000e+00\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9153 - accuracy: 0.0000e+00\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9090 - accuracy: 0.0000e+00\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9026 - accuracy: 0.0000e+00\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8962 - accuracy: 0.0000e+00\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8900 - accuracy: 0.0000e+00\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8838 - accuracy: 0.0000e+00\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8778 - accuracy: 0.0000e+00\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8719 - accuracy: 0.0000e+00\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8662 - accuracy: 0.0000e+00\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8606 - accuracy: 0.0000e+00\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8551 - accuracy: 0.0000e+00\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8498 - accuracy: 0.0000e+00\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8447 - accuracy: 0.0000e+00\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8398 - accuracy: 0.0000e+00\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8349 - accuracy: 0.0000e+00\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8304 - accuracy: 0.0000e+00\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.8262 - accuracy: 0.0000e+00\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8221 - accuracy: 0.0000e+00\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8179 - accuracy: 0.0000e+00\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8135 - accuracy: 0.0000e+00\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8091 - accuracy: 0.0000e+00\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8048 - accuracy: 0.0000e+00\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.8005 - accuracy: 0.0000e+00\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7962 - accuracy: 0.0000e+00\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7918 - accuracy: 0.0000e+00\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7874 - accuracy: 0.0000e+00\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7830 - accuracy: 0.0000e+00\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7784 - accuracy: 0.0000e+00\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7738 - accuracy: 0.0000e+00\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7690 - accuracy: 0.0000e+00\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7645 - accuracy: 0.0000e+00\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7602 - accuracy: 0.0000e+00\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7560 - accuracy: 0.0000e+00\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7517 - accuracy: 0.0000e+00\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7475 - accuracy: 0.0000e+00\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7434 - accuracy: 0.0000e+00\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7395 - accuracy: 0.0000e+00\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7357 - accuracy: 0.0000e+00\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7318 - accuracy: 0.0000e+00\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7280 - accuracy: 0.0000e+00\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7242 - accuracy: 0.0000e+00\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7204 - accuracy: 0.0000e+00\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7166 - accuracy: 0.0000e+00\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7128 - accuracy: 0.0000e+00\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7091 - accuracy: 0.0000e+00\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.7055 - accuracy: 0.0000e+00\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7018 - accuracy: 0.0000e+00\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6980 - accuracy: 0.0000e+00\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6943 - accuracy: 0.0000e+00\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6906 - accuracy: 0.0000e+00\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6869 - accuracy: 0.0000e+00\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6832 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1902a4e4070>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain, ytrain,epochs=150,callbacks =[tensorboard] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4756 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(xtest,ytest)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11661702],\n",
       "       [0.63367605],\n",
       "       [7.195854  ],\n",
       "       [0.04007149],\n",
       "       [0.22301912],\n",
       "       [0.20610213]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = model.predict(xtest)\n",
    "ypred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_ax = range(len(ypred)) \n",
    "plt.scatter(x_ax, ytest, s=10, color=\"blue\", label=\"original\")\n",
    "plt.plot(x_ax, ypred, lw=0.8, color=\"red\", label=\"predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11235458]\n",
      " [0.03002214]]\n"
     ]
    }
   ],
   "source": [
    "test_rownet = np.asarray(test_row_standarized) #testrow to model data without H, Hlab and TOC\n",
    "test_rownet = test_rownet.reshape(2,19,1)\n",
    "testpred = model.predict(test_rownet)\n",
    "print(testpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
